#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
retry_permanent.py - ä¸“é—¨å¤„ç†æ°¸ä¹…å¤±è´¥è¯çš„é‡è¯•è„šæœ¬

åŠŸèƒ½ï¼š
- è¯»å– failed_permanent.json ä¸­çš„æ°¸ä¹…å¤±è´¥è¯
- ä½¿ç”¨æœ€æ–°ä¼˜åŒ–çš„æ¨¡æ¿é‡æ–°å°è¯•ç”Ÿæˆ
- æˆåŠŸçš„è¯ä»æ°¸ä¹…å¤±è´¥æ¸…å•ç§»é™¤å¹¶åŠ å…¥è¯åº“
- ä»å¤±è´¥çš„è¯ä¿ç•™åœ¨æ°¸ä¹…å¤±è´¥æ¸…å•ä¸­
"""

import os
import json
import time
from datetime import datetime
from tqdm import tqdm

# é‡ç”¨ pipeline.py çš„æ ¸å¿ƒå‡½æ•°å’Œé…ç½®
import sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from pipeline import (
    PERM_FAILED_FILE, WORDS_REPO, DEEPSEEK_API_KEY,
    RETRY_BATCH_SIZE, RETRY_MAX_RETRY, FUNCTION_WORDS,
    _load_repo_dict, _save_repo, repo_lock,
    call_glm, extract_json_block, quality_checks, check_coverage,
    validate, SCHEMA, split_batches, run_batch_adaptive,
    load_function_words, create_smart_retry_prompt,
    _count_repo
)

# ä¸“ç”¨äºæ°¸ä¹…å¤±è´¥è¯çš„è¶…å®½æ¾æ¨¡æ¿
PERMANENT_RETRY_PROMPT = """
ä¸ºä»¥ä¸‹æ°¸ä¹…å¤±è´¥çš„è‹±è¯­å•è¯ç”Ÿæˆ JSON æ•°ç»„ï¼ˆä»…è¾“å‡º JSONï¼Œæ— å…¶ä»–æ–‡å­—ï¼‰ï¼š

ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ç¤ºä¾‹ï¼š
[
  {{
    "word": "example",
    "parts_of_speech": ["noun"],
    "pos_meanings": [
      {{"pos": "noun", "cn": "ä¾‹å­ï¼Œç¤ºä¾‹"}}
    ],
    "phrases": [],
    "sentences": [],
    "pronunciation": {{"US": {{"ipa": null, "audio": null}}}}
  }}
]

å…³é”®è¦æ±‚ï¼š
1. pos_meanings å¿…é¡»æ˜¯å¯¹è±¡æ•°ç»„ï¼æ ¼å¼ï¼š[{{"pos": "è¯æ€§", "cn": "ä¸­æ–‡"}}]
2. åŠŸèƒ½è¯ã€æ•°å­—è¯å¯ä»¥ phrases ç•™ç©ºï¼š[]
3. æ¯ä¸ªå¯¹è±¡éƒ½å¿…é¡»åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µ
4. ä¸¥æ ¼éµå¾ª JSON æ ¼å¼ï¼Œæ³¨æ„å¼•å·å’Œé€—å·

å•è¯åˆ—è¡¨ï¼š{words}
"""

def load_permanent_failed():
    """åŠ è½½æ°¸ä¹…å¤±è´¥è¯æ¸…å•"""
    if not os.path.exists(PERM_FAILED_FILE):
        print(f"âŒ æ²¡æœ‰æ‰¾åˆ° {PERM_FAILED_FILE} æ–‡ä»¶")
        return []
    
    try:
        with open(PERM_FAILED_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)
        print(f"ğŸ“‹ åŠ è½½æ°¸ä¹…å¤±è´¥è¯ï¼š{len(data)} ä¸ª")
        return data
    except Exception as e:
        print(f"âŒ è¯»å– {PERM_FAILED_FILE} å¤±è´¥ï¼š{e}")
        return []

def save_permanent_failed(failed_words):
    """æ›´æ–°æ°¸ä¹…å¤±è´¥è¯æ¸…å•"""
    try:
        with open(PERM_FAILED_FILE, "w", encoding="utf-8") as f:
            json.dump(sorted(list(set(failed_words))), f, ensure_ascii=False, indent=2)
        print(f"ğŸ“Œ æ›´æ–°æ°¸ä¹…å¤±è´¥è¯æ¸…å•ï¼š{len(failed_words)} ä¸ª")
    except Exception as e:
        print(f"âŒ å†™å…¥ {PERM_FAILED_FILE} å¤±è´¥ï¼š{e}")

def deduplicate_failed_words(failed_words, repo_dict):
    """
    å»é‡æ°¸ä¹…å¤±è´¥è¯ï¼šæ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨äºè¯åº“ä¸­
    Args:
        failed_words: æ°¸ä¹…å¤±è´¥è¯åˆ—è¡¨
        repo_dict: ç°æœ‰è¯åº“å­—å…¸
    Returns:
        tuple: (éœ€è¦é‡è¯•çš„è¯, å·²å­˜åœ¨çš„è¯, çœŸæ­£ä¸¢å¤±çš„è¯)
    """
    words_to_retry = []  # ç¡®å®ä¸åœ¨è¯åº“ä¸­ï¼Œéœ€è¦é‡è¯•çš„è¯
    already_exists = []  # å·²ç»å­˜åœ¨äºè¯åº“ä¸­çš„è¯
    
    print("ğŸ” å¼€å§‹å»é‡æ£€æŸ¥æ°¸ä¹…å¤±è´¥è¯...")
    
    for word in failed_words:
        word_lower = word.lower().strip()
        if word_lower in repo_dict:
            already_exists.append(word)
            print(f"âœ… è¯æ±‡ '{word}' å·²å­˜åœ¨äºè¯åº“ä¸­ï¼Œå°†ä»å¤±è´¥åˆ—è¡¨ç§»é™¤")
        else:
            words_to_retry.append(word)
    
    print(f"ğŸ“Š å»é‡ç»“æœï¼š")
    print(f"   - éœ€è¦é‡è¯•çš„è¯ï¼š{len(words_to_retry)} ä¸ª")
    print(f"   - å·²å­˜åœ¨çš„è¯ï¼š{len(already_exists)} ä¸ª")
    
    if already_exists:
        print(f"ğŸ“ å·²å­˜åœ¨çš„è¯æ±‡ï¼š{already_exists[:10]}{'...' if len(already_exists) > 10 else ''}")
    
    return words_to_retry, already_exists

def build_permanent_prompt(words):
    """æ„å»ºæ°¸ä¹…å¤±è´¥è¯ä¸“ç”¨Prompt"""
    words_str = ", ".join(words)
    return PERMANENT_RETRY_PROMPT.format(words=words_str)

def retry_permanent_batch(repo_dict, words):
    """é‡è¯•ä¸€æ‰¹æ°¸ä¹…å¤±è´¥è¯"""
    try:
        prompt = build_permanent_prompt(words)
        raw = call_glm(prompt)
        
        # è°ƒè¯•è¾“å‡º
        print(f"ğŸ” AIåŸå§‹å›å¤ï¼ˆå‰200å­—ç¬¦ï¼‰ï¼š{raw[:200]}")
        
        json_block = extract_json_block(raw)
        print(f"ğŸ” æå–çš„JSONï¼ˆå‰200å­—ç¬¦ï¼‰ï¼š{json_block[:200]}")
        
        data = json.loads(json_block)
        print(f"ğŸ” è§£æåæ•°æ®ç±»å‹ï¼š{type(data)}, é•¿åº¦ï¼š{len(data) if isinstance(data, list) else 'N/A'}")
        
        # æ£€æŸ¥ç¬¬ä¸€ä¸ªé¡¹ç›®çš„ç»“æ„
        if isinstance(data, list) and len(data) > 0:
            first_item = data[0]
            print(f"ğŸ” ç¬¬ä¸€ä¸ªé¡¹ç›®çš„é”®ï¼š{list(first_item.keys()) if isinstance(first_item, dict) else 'Not a dict'}")
            if isinstance(first_item, dict) and 'pos_meanings' in first_item:
                pos_meanings = first_item['pos_meanings']
                print(f"ğŸ” pos_meaningsç±»å‹ï¼š{type(pos_meanings)}, å†…å®¹ï¼š{pos_meanings}")
                if isinstance(pos_meanings, list) and len(pos_meanings) > 0:
                    print(f"ğŸ” ç¬¬ä¸€ä¸ªpos_meaningsé¡¹ï¼š{pos_meanings[0]}")
        
        validate(instance=data, schema=SCHEMA)
        
        # ä½¿ç”¨æœ€å®½æ¾çš„è´¨é‡æ£€æŸ¥
        bad = quality_checks(data)
        if bad:
            print(f"âš ï¸ è´¨é‡æ£€æŸ¥å‘ç°é—®é¢˜ï¼š{bad[:3]}...")
            return False, [], f"quality-check-failed: {len(bad)} issues"
        
        # è¦†ç›–ç‡æ£€æŸ¥
        ok, diff = check_coverage(words, data)
        if not ok:
            return False, [], f"coverage-failed: missing={diff['missing']}, extras={diff['extras']}"
        
        # æˆåŠŸï¼šä¿å­˜åˆ°è¯åº“
        with repo_lock:
            added = updated = 0
            for item in data:
                w = (item.get("word") or "").lower()
                if w in repo_dict:
                    updated += 1
                else:
                    added += 1
                repo_dict[w] = item
            _save_repo(repo_dict)
        
        return True, [w.lower() for w in words], f"added={added}, updated={updated}"
        
    except Exception as e:
        print(f"ğŸ” è¯¦ç»†é”™è¯¯ä¿¡æ¯ï¼š{repr(e)}")
        import traceback
        print(f"ğŸ” å®Œæ•´å †æ ˆï¼š{traceback.format_exc()}")
        return False, [], f"exception: {repr(e)}"

def main():
    print("ğŸ”„ æ°¸ä¹…å¤±è´¥è¯é‡è¯•è„šæœ¬å¯åŠ¨...")
    
    if not DEEPSEEK_API_KEY:
        print("âŒ è¯·è®¾ç½® DEEPSEEK_API_KEY")
        return
    
    # åŠ è½½æ•°æ®
    failed_words = load_permanent_failed()
    if not failed_words:
        return
    
    repo_dict = _load_repo_dict()
    print(f"ğŸ“š å½“å‰è¯åº“ï¼š{_count_repo(repo_dict)} è¯")
    
    # é‡æ–°åŠ è½½æœ€æ–°çš„åŠŸèƒ½è¯ç™½åå•
    global FUNCTION_WORDS
    FUNCTION_WORDS = load_function_words()
    print(f"ğŸ›¡ï¸ åŠŸèƒ½è¯ç™½åå•ï¼š{len(FUNCTION_WORDS)} ä¸ª")
    
    # å»é‡ï¼šæ£€æŸ¥æ°¸ä¹…å¤±è´¥è¯æ˜¯å¦å·²å­˜åœ¨äºè¯åº“ä¸­
    words_to_retry, already_exists = deduplicate_failed_words(failed_words, repo_dict)
    
    # å¦‚æœæœ‰è¯å·²å­˜åœ¨ï¼Œç«‹å³æ›´æ–°æ°¸ä¹…å¤±è´¥æ¸…å•
    if already_exists:
        print(f"ğŸ—‘ï¸  å‘ç° {len(already_exists)} ä¸ªè¯å·²å­˜åœ¨äºè¯åº“ä¸­ï¼Œç«‹å³ä»æ°¸ä¹…å¤±è´¥æ¸…å•ç§»é™¤")
        save_permanent_failed(words_to_retry)
    
    # å¦‚æœæ²¡æœ‰éœ€è¦é‡è¯•çš„è¯ï¼Œç›´æ¥é€€å‡º
    if not words_to_retry:
        print("ğŸ‰ æ‰€æœ‰æ°¸ä¹…å¤±è´¥è¯éƒ½å·²å­˜åœ¨äºè¯åº“ä¸­ï¼Œæ— éœ€é‡è¯•ï¼")
        return
    
    print(f"ğŸ¯ å®é™…éœ€è¦é‡è¯•çš„è¯æ•°ï¼š{len(words_to_retry)} ä¸ª")
    
    # åˆ†æ‰¹å¤„ç†éœ€è¦é‡è¯•çš„è¯
    batches = split_batches(words_to_retry, RETRY_BATCH_SIZE)
    print(f"ğŸ¯ åˆ†ä¸º {len(batches)} ä¸ªæ‰¹æ¬¡ï¼Œæ¯æ‰¹ {RETRY_BATCH_SIZE} è¯")
    
    succeeded_words = []
    still_failed_words = []
    
    prog = tqdm(total=len(batches), desc="é‡è¯•æ°¸ä¹…å¤±è´¥è¯")
    
    for i, batch_words in enumerate(batches, 1):
        print(f"\nğŸ“¦ å¤„ç†æ‰¹æ¬¡ {i}/{len(batches)}: {batch_words}")
        
        success, success_words, reason = retry_permanent_batch(repo_dict, batch_words)
        
        if success:
            succeeded_words.extend(success_words)
            print(f"âœ… æ‰¹æ¬¡ {i} æˆåŠŸï¼š{reason}")
        else:
            still_failed_words.extend([w.lower() for w in batch_words])
            print(f"âŒ æ‰¹æ¬¡ {i} ä»å¤±è´¥ï¼š{reason}")
        
        prog.update(1)
        time.sleep(1.0)  # é˜²æ­¢APIé™æµ
    
    prog.close()
    
    # æ±‡æ€»ç»“æœ
    print(f"\nğŸ¯ å¤„ç†ç»“æœæ±‡æ€»ï¼š")
    print(f"ğŸ“‹ åŸå§‹æ°¸ä¹…å¤±è´¥è¯æ•°ï¼š{len(failed_words)} è¯")
    print(f"ğŸ—‘ï¸  å·²å­˜åœ¨äºè¯åº“ï¼š{len(already_exists)} è¯")
    print(f"ğŸ”„ å®é™…é‡è¯•è¯æ•°ï¼š{len(words_to_retry)} è¯")
    print(f"âœ… æˆåŠŸæ•‘å›ï¼š{len(succeeded_words)} è¯")
    print(f"âŒ ä»ç„¶å¤±è´¥ï¼š{len(still_failed_words)} è¯")
    print(f"ğŸ“š è¯åº“æ€»æ•°ï¼š{_count_repo(repo_dict)} è¯")
    
    if already_exists:
        print(f"ğŸ‰ å·²å­˜åœ¨è¯æ±‡ï¼š{already_exists[:10]}{'...' if len(already_exists) > 10 else ''}")
    
    if succeeded_words:
        print(f"ğŸ‰ æˆåŠŸè¯æ±‡ï¼š{succeeded_words[:10]}{'...' if len(succeeded_words) > 10 else ''}")
    
    if still_failed_words:
        print(f"ğŸ”´ ä»å¤±è´¥è¯æ±‡ï¼š{still_failed_words[:10]}{'...' if len(still_failed_words) > 10 else ''}")
    
    # æ›´æ–°æ°¸ä¹…å¤±è´¥æ¸…å•ï¼ˆåªä¿ç•™ä»ç„¶å¤±è´¥çš„è¯ï¼‰
    if len(still_failed_words) != len(failed_words):
        save_permanent_failed(still_failed_words)
        print(f"ğŸ“ æ°¸ä¹…å¤±è´¥æ¸…å•å·²æ›´æ–°")
    
    # ç”ŸæˆæŠ¥å‘Š
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_file = f"retry_permanent_report_{timestamp}.txt"
    
    with open(report_file, "w", encoding="utf-8") as f:
        f.write(f"æ°¸ä¹…å¤±è´¥è¯é‡è¯•æŠ¥å‘Š - {timestamp}\n")
        f.write(f"=" * 50 + "\n\n")
        f.write(f"åŸå§‹æ°¸ä¹…å¤±è´¥è¯æ•°ï¼š{len(failed_words)}\n")
        f.write(f"å·²å­˜åœ¨äºè¯åº“è¯æ•°ï¼š{len(already_exists)}\n")
        f.write(f"å®é™…é‡è¯•è¯æ•°ï¼š{len(words_to_retry)}\n")
        f.write(f"æˆåŠŸæ•‘å›è¯æ•°ï¼š{len(succeeded_words)}\n")
        f.write(f"ä»ç„¶å¤±è´¥è¯æ•°ï¼š{len(still_failed_words)}\n")
        
        if words_to_retry:
            f.write(f"é‡è¯•æˆåŠŸç‡ï¼š{len(succeeded_words)/len(words_to_retry)*100:.1f}%\n")
        f.write(f"æ€»ä½“æ•‘å›ç‡ï¼š{(len(already_exists) + len(succeeded_words))/len(failed_words)*100:.1f}%\n\n")
        
        if already_exists:
            f.write("å·²å­˜åœ¨äºè¯åº“çš„è¯æ±‡ï¼š\n")
            f.write(", ".join(already_exists) + "\n\n")
        
        if succeeded_words:
            f.write("æˆåŠŸæ•‘å›çš„è¯æ±‡ï¼š\n")
            f.write(", ".join(succeeded_words) + "\n\n")
        
        if still_failed_words:
            f.write("ä»ç„¶å¤±è´¥çš„è¯æ±‡ï¼š\n")
            f.write(", ".join(still_failed_words) + "\n\n")
    
    print(f"ğŸ“Š è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³ï¼š{report_file}")
    print("ğŸ æ°¸ä¹…å¤±è´¥è¯é‡è¯•å®Œæˆï¼")

if __name__ == "__main__":
    main()